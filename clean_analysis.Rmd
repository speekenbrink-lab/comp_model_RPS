---
output:
  html_document: default
  word_document: default
---
--
title: "opponent modelling"
author: "Ismail Guennouni"
date: "30 July 2018"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
dat <- read.csv("data20180719.csv")
```

```{r}
# using some functions dplyr, ggpubr, PairedData and sjPlot. Need to be loaded. 
library(tidyr)
library(dplyr)
library(MASS)
library(ggpubr)
library(PairedData)
library(multcompView)
library(lsmeans)


# transform 'winner' variable in numeric score
dat$score <- recode(dat$winner, human = 1, tie = 0, ai = -1)
# create a new variable 'block' with round 1...25 = block 1 and round 26...50 as block 2
dat$block <- factor(as.numeric(cut(dat$round,2)),labels =c("first half", "second half"))

# create a new variable "game.f" as a factor variable of games
dat$game.f <- factor(dat$game, labels = c("RPS","FWG","NUM"),levels=c("rps","fwg","numbers"))

# overall score to pay bonuses 
dat_score <- dat %>% 
  group_by(human_id) %>% 
      summarize(overall_score = sum(score))
(avg_bonus <- floor(mean(abs(dat_score$overall_score))))*0.02

#Group data by human_id and calculate mean score per block of each game.
dat2 <- dat %>% 
  group_by(human_id,condition,game,block,game.f) %>% 
      summarize(block_score = mean(score))

# Group data by game and ID
dat3 <- group_by(dat2, human_id,game.f,game) %>% summarise(game_score = mean(block_score))
# head(dat3,6)

# Subsetting scores data by game
rps <- subset(dat3,  game.f == "RPS",game_score)
fwg <- subset(dat3,  game.f == "FWG",game_score)
num <- subset(dat3,  game.f == "NUM",game_score)
# head(rps,6)
```


```{r}
# Look at some summary statistics of group means #############################

group_by(dat2, game.f) %>%
  summarise(
    mean = mean(block_score, na.rm = TRUE),
    sd = sd(block_score, na.rm = TRUE)
  )



group_by(dat2, game.f, block) %>%
  summarise(
    count = n(),
    mean = mean(block_score, na.rm = TRUE),
    sd = sd(block_score, na.rm = TRUE)
  )


group_by(dat2, game.f, condition,block) %>%
  summarise(
    count = n(),
    mean = mean(block_score, na.rm = TRUE),
    sd = sd(block_score, na.rm = TRUE)
  )
```


```{r}
# PLOTS  #############################

# Plot scores per game 

ggboxplot(dat3, x = "game.f", y = "game_score", group = 1, add =c("mean_ci","jitter"), color="game.f", palette = c("#00AFBB", "#E7B800", "#FC4E07"), order = c("RPS", "FWG","NUM"), ylab = "Score", xlab = "Games") 

ggerrorplot(dat3, x = "game.f", y = "game_score", group = 1, color="game.f", desc_stat = "mean_ci",palette = c("#00AFBB", "#E7B800", "#FC4E07"), order = c("RPS", "FWG","NUM"), ylab = "Score", xlab = "Games") 


# Plot paired scores between games
#pd <- paired(rps,fwg)
#pd2 <- paired(fwg,num)
#head(pd)
#plot(pd, type = "profile")
#plot(pd2, type = "profile")
ggpaired(dat3, x = "game.f", y = "game_score",color = "game.f", id = "human_id", line.color = "gray", line.size = 0.4, palette = "npg")

# Plot results by game and block (for all 3 games, learning is happening) 
ggboxplot(dat2, x = "game", y = "block_score", palette = c("#00AFBB", "#E7B800"),order = c("rps", "fwg","numbers"), fill="block",ylab = "Percentage score", xlab = "Games")


# Group data by game and ID
dat4 <- group_by(dat2, human_id,condition,game.f) %>% summarise(game_score = mean(block_score))

# Level 2 is harder to win against than level 1
ggboxplot(dat2, x = "condition", y = "block_score", palette = c("#00AFBB", "#E7B800"), fill="condition",ylab = "Percentage score", xlab = "Conditions")

ggerrorplot(dat2, x = "condition", y = "block_score", desc_stat = "mean_ci" , palette = c("#00AFBB", "#E7B800"), color="condition",ylab = "Percentage score", xlab = "Conditions")

# Main effect of block 
ggerrorplot(dat2, x = "block", y = "block_score", desc_stat = "mean_ci" , palette = c("#00AFBB", "#E7B800"), color="block",ylab = "Percentage score", xlab = "Block")

# Breaking it down by game (seems to be true for RPS and FWG, less so for Numbers )
ggboxplot(dat4, x = "game.f", y = "game_score", palette = c("#00AFBB","#E7B800","#FC4E07"), fill="condition",order = c("RPS", "FWG","NUM"),ylab = "Game Score", xlab = "Conditions")

```



```{r}
# Testing score against hypothesis of random play  ######################################

# Normality of scores 
shapiro.test(dat3$game_score)

# Testing Scores against random play (expected 0 average score)
t.test(as.numeric(rps$game_score), mu = 0, alternative = "two.sided")
t.test(as.numeric(fwg$game_score), mu = 0, alternative = "two.sided")
t.test(as.numeric(num$game_score), mu = 0, alternative = "two.sided")

```


```{r}
# AFEX PACKAGE FOR RUNNING RM ANOVA AND POST HOC TESTS ############################
citation(package = "afex", lib.loc = NULL, auto = NULL)
library(afex)
a1 <- aov_car( block_score ~ game.f*block*condition + Error(human_id/(game.f*block)), dat2)
summary(a1)
(a1_nice <- nice(a1, es = attr(a1$anova_table, "es"),
  observed = attr(a1$anova_table, "observed"),
  correction = attr(a1$anova_table, "correction"), MSE = NULL,
  intercept = NULL, p_adjust_method = attr(a1$anova_table,
  "p_adjust_method"), sig_symbols = attr(a1$anova_table, "sig_symbols")))

write.table(a1_nice,file = "a1.txt", sep = ",", quote = FALSE, row.names = F)

## Note to Self: no need to worry abour the HF warning. You don't have pb with sphericity according to Mauchly tests, and the warning only applies to Huynh-Feldt corrections for violations of sphericity. 
```

```{r}
#Pair waise comparison and post hoc tests for the interaction: Game * Block using lsmeans 

# game score differences statistically significant?
(ls0 <- lsmeans(a1, "game.f"))
(lsm0 <- update(pairs(ls0, reverse = TRUE), by=NULL, adjust = "holm"))


# Main effect of block 
(ls01 <- lsmeans(a1, "block"))
(lsm01 <- update(pairs(ls01, reverse = TRUE), by=NULL, adjust = "holm"))
lsmip(a1, ~block)

# Main effect of condition
(ls02 <- lsmeans(a1, "condition"))
(lsm02 <- update(pairs(ls02, reverse = TRUE), by=NULL, adjust = "holm"))


# Pairwise comparison of first halves by game ( first half RPS vs first half WFG scores....)
(ls1 <- lsmeans(a1, "game.f", by="block"))
(lsm1 <- update(pairs(ls1, reverse = TRUE), by=NULL, adjust = "holm"))
plot(lsm1,by="block")
lsmip(a1, game.f ~ block)


# Pairwise comparison of each game score by block (first half RPS vs second half RPS....) + Control for family wise error:
ls2 <- lsmeans(a1, c("block","game.f"))
(lsm2 <- update(pairs(ls2, reverse = TRUE), by=NULL, adjust = "holm"))
(contr2 <- contrast(ls2, list(G1H2vG2H1 = c(0,1,-1,0,0,0))))
(contr3 <- contrast(ls2, list(G1H1vs0 = c(1,0,0,0,0,0))))
lsmip(a1, block ~ game.f)
lsmip(a1, ~ block * game.f)


# Pairwise comparison of scores facing the two types of players by game: 
lsc <- lsmeans(a1, "condition", by="game.f")
(lsmc <- update(pairs(lsc), by=NULL, adjust = "holm"))
plot(lsmc,by="game.f")
lsmip(a1, condition ~ game.f)


```

```{r}
#Pair waise comparison and post hoc tests : Game by Block and Condition



#library(multcompView)
#use cld to check for comparison pairs belonging to same group, meaning not significantly different from each other...
#cld(lsm4)


#plots
ls4 <- lsmeans(a1, "block",c("condition","game.f"))
ls4
(lsm4 <- update(pairs(ls4, reverse = TRUE), by=NULL, adjust = "holm"))


plot(lsm4,by="game.f")
lsmip(a1, game.f ~ block | condition)


# Interaction plot of game and block by condition 
lsmip(a1, game.f ~ block | condition)
lsmip(a1, condition ~ block * game.f)
```


```{r}
# Transfer harder for level2 opponent than when facing level 1 opponent? 
# learning to specifiy contrasts - 
# the below compares the score on each block and game for each type and tells me which scores belong to same group
# the idea is that if transfer is harder vs lvl2 player, then fwg first half score for lvl2 facing player should be sig lower than fwg first-half score vs lvl1 agent.not the case here as thye belong to same group.

(means.int <- lsmeans(a1, specs = c("game.f","block","condition")))

# Transfer level1: compare H1FWG with H1RPS 
con1  <- contrast(means.int, list(H1_G2vsH1_G1forlvl1 = c(-1,1,0,0,0,0,0,0,0,0,0,0), H1_G3vsH1_G1forlvl1=c(-1,0,1,0,0,0,0,0,0,0,0,0)))
summary(con1, adjust = "holm")

# Transfer level2: compare H1FWG with H1RPS 
con2  <- contrast(means.int, list(H1_G2vsH1_G1forlvl2 = c(0,0,0,0,0,0,-1,1,0,0,0,0), H1_G3vsH1_G1forlvl2=c(0,0,0,0,0,0,-1,0,1,0,0,0)))
summary(con2, adjust = "holm")


# compare first half (H1) scores between level 1 and level 2 players in FWG and NUM
con3 <- contrast(means.int, list(G1vG2forH1 = c(0,1,0,0,0,0,0,-1,0,0,0,0), G2vG3forh1=c(0,0,1,0,0,0,0,0,-1,0,0,0)))
summary(con3, adjust ="holm")


# Within game learning harder for level2 opponent than when facing level 1 opponent? compare differences between block for each game and type
con4 <- contrast(means.int, list(L2vL1forRPS = c(1,0,0,-1,0,0,-1,0,0,1,0,0), L2vL1forFWG=c(0,1,0,0,-1,0,0,-1,0,0,1,0), L2vL1forNUM=c(0,0,1,0,0,-1,0,0,-1,0,0,1)))
summary(con4, adjust ="holm")

```






```{r}

#looking at TRIALS 2 to 6 to test robustness of evidence for transfer of learning of opponent strategy #########

dat_26 <- subset(dat,round >1 & round <7, drop =TRUE)
dat2_6 <- dat_26 %>% 
  group_by(human_id,condition,game.f,confidence,difficulty) %>% 
      summarise(early_score = mean(score))

# Check group means and SDs
group_by(dat2_6, game.f) %>%
  summarise(
    count = n(),
    mean = mean(early_score, na.rm = TRUE),
    sd = sd(early_score, na.rm = TRUE)
    )
group_by(dat2_6, game.f,condition) %>%
  summarise(
    count = n(),
    mean = mean(early_score, na.rm = TRUE),
    sd = sd(early_score, na.rm = TRUE)
    )
# plot scores per game 
ggerrorplot(dat2_6, x = "game.f", y = "early_score", group = 1, color="game.f", desc_stat = "mean_ci",palette = c("#00AFBB", "#E7B800", "#FC4E07"), order = c("RPS", "FWG","NUM"), ylab = "Score", xlab = "Games") 


# testing differences between early scores across games 
library(afex)
aov_early <- aov_car(early_score ~ game.f*condition + Error(human_id/(game.f)),data=dat2_6)
summary(aov_early)

aov_ear_nice <- nice(aov_early, es = attr(aov_early$anova_table, "es"),
  observed = attr(aov_early$anova_table, "observed"),
  correction = attr(aov_early$anova_table, "correction"), MSE = NULL,
  intercept = NULL, p_adjust_method = attr(aov_early$anova_table,
  "p_adjust_method"), sig_symbols = attr(aov_early$anova_table, "sig_symbols"))

write.table(aov_ear_nice,file = "aov_ear.txt", sep = ",", quote = FALSE, row.names = F)


# including confidence 

aov_conf_26 <- aov_car(early_score ~ game.f*condition*difficulty + Error(human_id/(game.f)),data=dat2_6)
summary(aov_conf_26)





(ls4 <- lsmeans(aov_early, "game.f"))
(summary(ls4, infer = c(TRUE,TRUE), null = 0,level = 0.95, adjust = "bon"))


(means.int2 <- lsmeans(aov_early, specs = c("game.f","condition")))
(trans26 <- summary(means.int2, infer = c(TRUE,TRUE),level = .95, adjust = "none",ref=c("FWG","NUM")))
(contr26 <- contrast(means.int2, list(G2L1vsG2L2 = c(0,1,0,0,-1,0))))


write.table(format(trans26, digits=2),file = "trans26.txt", sep = ",", quote = FALSE, row.names = F)

# compare early scores in FWG for lvl 1 and lvl2 / same for NUM

contrast(means.int2, list(G1vG2for26 = c(0,1,0,0,-1,0), G2vG3for26=c(0,0,1,0,0,-1)))
         
# Plot interactions for early rouns, condition by game

lsmip(aov_early, ~ game.f | condition )


# plots overall effect by game :
ggboxplot(dat2_6,"game.f", "early_score", fill = "game.f",palette = c("#00AFBB", "#E7B800", "#FC4E07"),order = c("RPS","FWG","NUM"))

# Note to Self: possible future work exstension is to pick the guys who scored highly on the first rounds of the second game and fit the various learning models to them only. 
# Two ways to test learning: compare first half between games for different conditions 
# compare early score between games for different conditions 
# Check whteher confidence and difficulty  -> add them as covariates in big anova and early score anova *confidence*difficulty.... --> too hard to interpret 

# do a model comparison with model without confidence and difficulty -> start witn ANCOVA (try and see what happens with various interactions).  
```


```{r}
# adding confidence and difficulty feedback 
datcd <- dat %>% 
  group_by(human_id,condition,confidence,difficulty) %>% 
      summarise(avg_score = mean(score))

# testing conf, diff and score for normality 
shapiro.test(datcd$avg_score)
shapiro.test(datcd$confidence)
shapiro.test(datcd$difficulty)

# histograms 
hist(datcd$confidence, breaks = 20)
hist(datcd$difficulty, breaks=10)

# descriptive stats 
group_by(datcd, condition) %>%
  summarise(
    count = n(),
    median = median(confidence, na.rm = TRUE),
    IQR = IQR(confidence, na.rm = TRUE)
  )

group_by(datcd, condition) %>%
  summarise(
    count = n(),
    median = median(difficulty, na.rm = TRUE),
    IQR = IQR(difficulty, na.rm = TRUE)
  )
# Comparing confidence and difficulty by condition
(res1 <- wilcox.test(confidence ~ condition, data = datcd,exact = FALSE))
(res2 <- wilcox.test(difficulty ~ condition, data = datcd,exact = FALSE))

# Correlation confidence difficulty and score: 
mat <- as.matrix(datcd[,unlist(lapply(datcd, is.numeric))])
cor.test(datcd$confidence, datcd$avg_score, method="spearman")
cor.test(datcd$difficulty, datcd$avg_score, method="spearman")


# Transforming confidence into 4 lvl factor
datcd$confidence.f <- factor(as.numeric(cut(datcd$confidence,2)),labels =c("low conf","high conf"))
summary(datcd$confidence.f)
table(datcd$confidence.f,datcd$condition)

#  explore interaction block confidence
#(lsm7 <- lsmeans(acd, c("confidence.f","block")))
#(update(pairs(lsm7, reverse = TRUE, adjust = "holm"), by=NULL))
#plot(lsm7, by ="confidence.f")
#lsmip(acd, confidence.f ~ block)

#
#(lsm8 <- lsmeans(acd, c("confidence.f","block","game.f")))
#lsmip(acd, confidence.f ~ block*game.f)
# checking that low confidence NUMBERS play is not different from random play
#con3 <- contrast(lsm8, list(G1vG2forconf = c(0,0,0,0,0,0,0,0,0,0,1,0)))
#summary(con3, adjust ="holm")

# low and high confidence players have similar initial score in RPS
#con4 <- contrast(lsm8, list(HCvLCforRPS = c(-1,1,0,0,0,0,0,0,0,0,0,0)))
#summary(con4, adjust="holm")
```




```{r}
# ANCOVA with confidence as covariate 
dat_ancova <- dat %>% 
  group_by(human_id,game.f,condition,block,confidence,difficulty) %>% 
      summarise(avg_score = mean(score))
# Centering variables for ANCOVA 
dat_ancova$conf_cen <- scale(dat_ancova$confidence, center=TRUE, scale=FALSE) 
dat_ancova$diff_cen <- scale(dat_ancova$difficulty, center=TRUE, scale=FALSE) 

# run RM anova using afex library (ran anova including difficulty as well but wasn't significant)
library(afex)
acd <- aov_car( avg_score ~ game.f*block*condition + conf_cen + diff_cen + Error(human_id/(game.f*block)), factorize = FALSE,dat_ancova)
summary(acd)

nice(acd, es = attr(acd$anova_table, "es"),
  observed = attr(acd$anova_table, "observed"),
  correction = attr(acd$anova_table, "correction"), MSE = NULL,
  intercept = NULL, p_adjust_method = attr(acd$anova_table,
  "p_adjust_method"), sig_symbols = attr(acd$anova_table, "sig_symbols"))



# post hoc tests
(anc1 <- lsmeans(acd, c("conf_cen")))

(lsm6 <- lsmeans(acd, c("conf_cen","condition")))
update(pairs(lsm6, reverse = TRUE, adjust = "holm"), by=NULL)
plot(lsm6, by ="condition")
plot(lsm6, by ="conf_cen")
lsmip(acd, conf_cen ~ condition)


```


```{r}

# transform data by differencing two consecutive scores, filter for first and second transfer 
library(dplyr)
dat_test1 <- dat %>% 
  group_by(human_id,game.f,condition,block,confidence,difficulty) %>% 
      summarise(avg_score = mean(score)) %>%
         group_by(human_id) %>%
            mutate(diff_score = avg_score - lag(avg_score, default = 0)) %>%
              mutate(learn_phase =c("init RPS","within RPS","transfer 1","within WFG","transfer 2","within MOD"))

head(dat_test1)        
# define dataset with first transfer only 
dat_trans1 <- dat_test1 %>%
  filter (learn_phase == "transfer 1") %>%
    select(-c(game.f,block,avg_score,learn_phase))

head(dat_trans1)
# Data of transfer as difference between RPS_H2 and FWG_H1 is normally distributed
shapiro.test(dat_trans1$diff_score)


# Regression transfer score on condition and confidence
summary(lm(diff_score~ confidence + difficulty + factor(condition)+confidence*factor(condition), data = dat_trans1))

# tets hypothesis diff_score = 0 (transfer) against alternative it is negative -> No transfer
t.test( dat_trans1$diff_score, mu = 0 ,alternative = "less")

# To be sure.... Compare means of two condition 
t.test(dat_trans1$diff_score ~ condition, data = dat_trans1,exact = FALSE)

#DOING THE SAME FOR TRANSFER 2 : 

dat_trans2 <- dat_test1 %>%
  filter (learn_phase == "transfer 2") %>%
    select(-c(game.f,block,avg_score,learn_phase))

# Regression transfer score on condition and confidence -> no effects 
summary(lm(diff_score~ confidence + difficulty + factor(condition) + confidence*factor(condition), data = dat_trans2))
```


```{r}
# Does confidence moderate transfer ?
# Looking at early rounds only as proxy for transfer 
dat_fwg <- dat2_6 %>%
  filter (game.f == "FWG")
dat_num <- dat2_6 %>%
  filter (game.f == "NUM")

# correlation confidence and transfer as proxied by score in early rounds : 
shapiro.test(dat_fwg$confidence)
cor.test(dat_fwg$confidence, dat_fwg$early_score, method="spearman")
cor.test(dat_num$confidence, dat_num$early_score, method="spearman")


# model explaining early scores in fwg by confidene and condition -> no effects 
summary(lm(early_score ~ confidence*condition, data=dat_fwg))
summary(lm(early_score ~ confidence*condition, data=dat_num))

```

```{r}
# checking whether theta changes between games 

# lvl1 opponent 
bic <- read.csv("BIC_result.csv")
head(bic)

dat_lvl1 <- bic %>%
  select(c(id,condition,level2_3_theta1,level2_3_theta2,level2_3_theta3)) %>%
    gather(key = game, value = theta,-c(id,condition)) %>%
      group_by(id)
dat_lvl1$games <- factor(dat_lvl1$game, labels=c("RPS","FWG","MOD"),levels=c("level2_3_theta1","level2_3_theta2","level2_3_theta3"))

library(afex)
aov2 <- aov_car( theta ~ games + Error(id/(games)), dat_lvl1)
summary(aov2)

table2 <- nice(aov2, es = attr(aov2$anova_table, "es"),
  observed = attr(aov2$anova_table, "observed"),
  correction = attr(aov2$anova_table, "correction"), MSE = NULL,
  intercept = NULL, p_adjust_method = attr(aov2$anova_table,
  "p_adjust_method"), sig_symbols = attr(aov2$anova_table, "sig_symbols"))

kable(table2)

dat_lvl1 %>% 
  group_by(games) %>%
  summarise(theta.m = mean(theta),
            SD = sd(theta, na.rm =TRUE ))

#plot 
ggerrorplot(dat_lvl1, x = "games", y = "theta", group = 1, color="games", desc_stat = "mean_ci",palette = c("#00AFBB", "#E7B800", "#FC4E07"), order = c("RPS", "FWG","MOD"), ylab = "Theta", xlab = "Games") 


# lvl2 opponent 
dat_lvl2 <- bic %>%
  select(c(id,condition,level3_3_theta1,level3_3_theta2,level3_3_theta3)) %>%
    gather(key = game, value = theta,-c(id,condition)) %>%
      group_by(id)
dat_lvl2$games <- factor(dat_lvl2$game, labels=c("RPS","FWG","MOD"),levels=c("level3_3_theta1","level3_3_theta2","level3_3_theta3"))

# anova
aov3 <- aov_car( theta ~ games + Error(id/(games)), dat_lvl2)
summary(aov3)

table3 <- nice(aov3, es = attr(aov3$anova_table, "es"),
  observed = attr(aov3$anova_table, "observed"),
  correction = attr(aov3$anova_table, "correction"), MSE = NULL,
  intercept = NULL, p_adjust_method = attr(aov3$anova_table,
  "p_adjust_method"), sig_symbols = attr(aov3$anova_table, "sig_symbols"))

kable(table3)

# mean comparison
dat_lvl2 %>% 
  group_by(games) %>%
  summarise(theta.m = mean(theta),
            SD = sd(theta, na.rm =TRUE ))

require(gridExtra)
#plot lvl1 
plot1 <- ggerrorplot(dat_lvl1, x = "games", y = "theta", group = 1, color="games", desc_stat = "mean_ci",palette = c("#00AFBB", "#E7B800", "#FC4E07"), order = c("RPS", "FWG","MOD"), ylab = "Theta", xlab = "Games")
#plot lvl2
plot2 <- ggerrorplot(dat_lvl2, x = "games", y = "theta", group = 1, color="games", desc_stat = "mean_ci",palette = c("#00AFBB", "#E7B800", "#FC4E07"), order = c("RPS", "FWG","MOD"), ylab = "Theta", xlab = "Games") 


grid.arrange(plot1, plot2, ncol=2)

```












